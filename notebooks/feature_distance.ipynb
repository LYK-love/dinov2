{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to\n",
    "\n",
    "```sh\n",
    "sudo apt install ffmpeg libavcodec-extra\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download model checkpoints:\n",
    "# import torch\n",
    "\n",
    "# # dinov2_vits14_reg_lc = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14_reg_lc')\n",
    "# dinov2_vits14_reg_lc = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14_lc')\n",
    "\n",
    "# # Then move ckpt to dinov2/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if 'dinov2' in sys.modules:\n",
    "    del sys.modules['dinov2']\n",
    "    \n",
    "# Get the absolute path of the project root\n",
    "project_root = os.path.abspath(\"..\")  # Adjust path if your notebook is deeper in directories\n",
    "\n",
    "# Add project root to sys.path\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# sys.path.append(project_root)\n",
    "\n",
    "    \n",
    "# Now you can import dinov2\n",
    "import dinov2\n",
    "print(\"Currently using dinov2 from:\", dinov2.__file__)\n",
    "\n",
    "\n",
    "\n",
    "from dinov2.eval.setup import build_model_for_eval\n",
    "from dinov2.configs import load_and_merge_config\n",
    "from dinov2.utils.visualize import print_video_model_stats, load_and_preprocess_video, get_model_output, \\\n",
    "    two_stage_pca, compute_cosine_similarity, save_triple_image, plot_videos, plot_distance_chart\n",
    "\n",
    "device = \"cuda\"\n",
    "device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dinov2 (with registers) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = \"s\"\n",
    "with_registers = \"_reg4\" # \"_reg4\"\n",
    "# Use `dinov2_vits14_pretrain`\n",
    "conf = load_and_merge_config(f'eval/vit{model_size}14{with_registers}_pretrain')\n",
    "model = build_model_for_eval(conf, f'../dinov2/checkpoints/dinov2_vit{model_size}14{with_registers}_pretrain.pth')\n",
    "# model = build_model_for_eval(conf, f'../dinov2/checkpoints/dinov2_vit{model_size}14_pretrain.pth')\n",
    "\n",
    "THRESHOLD = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ndarray\n",
    "\n",
    "\n",
    "def compute_distance_in_feature_space(video1, video2, model, device, threshold=0.6):\n",
    "    B, C, H, W, patch_size, embedding_dim, patch_num = print_video_model_stats(video1, model)\n",
    "    \n",
    "    # Get cls token embedding and patch token embeddings\n",
    "    cls_token_emb1, patch_token_embs1 = get_model_output(model, video1)\n",
    "    cls_token_emb2, patch_token_embs2 = get_model_output(model, video2)\n",
    "    \n",
    "     # Calculate similarity\n",
    "     # Each cls token embedding is of shape (B, D) where B is the video length\n",
    "    similarities = compute_cosine_similarity(cls_token_emb1, cls_token_emb2)\n",
    "    normalized_distances = list(map(lambda sim: (1 - sim)/2, similarities))\n",
    "    return normalized_distances\n",
    "\n",
    "def plot(img1: np.ndarray, img2: np.ndarray, distance: float, output_path=None):\n",
    "    \"\"\"\n",
    "    Plots two images side by side with the computed distance displayed as a title.\n",
    "\n",
    "    Parameters:\n",
    "        img1 (np.ndarray): The first image (original).\n",
    "        img2 (np.ndarray): The second image (covered).\n",
    "        distance (float): The computed distance between the two images.\n",
    "        output_path (str, optional): Path to save the plot. If None, the plot is displayed.\n",
    "    \"\"\"\n",
    "    # Create figure with stacked images (one above the other)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 12))\n",
    "\n",
    "    ax1.imshow(img1)\n",
    "    ax1.set_title(\"Original\")\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.imshow(img2)\n",
    "    ax2.set_title(\"Covered\")\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"Distance: {distance:.6f}\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save or display the figure\n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"./data/pong/videos\"\n",
    "video1_name, video2_name = \"pong\", \"pong\"\n",
    "video1_path, video2_path = os.path.join(base_dir, f\"{video1_name}.avi\"), os.path.join(base_dir, f\"{video2_name}.avi\")\n",
    "output_dir = \"./data/pong/plots/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "from dinov2.utils.visualize import colorize_area\n",
    "colorize_video2_hook = lambda video: colorize_area(video, color=[0, 255, 0], starting_location=(35, 17), width=4, height=4)  # Change the pixel at (0, 0) to black\n",
    "\n",
    "video1_prenorm, video1_normalized, fps = load_and_preprocess_video(video1_path, target_size=448*1, patch_size = model.patch_size)# 448 is multiples of patch_size (14)\n",
    "video2_prenorm, video2_normalized, fps = load_and_preprocess_video(video2_path, target_size=448*1, patch_size = model.patch_size, hook_function=colorize_video2_hook)# 448 is multiples of patch_size (14)\n",
    "\n",
    "\n",
    "distance_list = compute_distance_in_feature_space(video1_prenorm, video2_prenorm, model, device)\n",
    "\n",
    "video1_prenorm = video1_prenorm.permute(0, 2, 3, 1).cpu().numpy()  # Change to (T, H, W, C)\n",
    "video2_prenorm = video2_prenorm.permute(0, 2, 3, 1).cpu().numpy()  # Change to (T, H, W, C)\n",
    "T, H, W, C = video1_prenorm.shape\n",
    "\n",
    "for t in range(T):\n",
    "    if t > 3:\n",
    "        break\n",
    "    frame1, frame2 = video1_prenorm[t], video2_prenorm[t]\n",
    "    distance = distance_list[t]\n",
    "    \n",
    "    plot(frame1, frame2, distance, output_path=None)\n",
    "    print(f\"Distance at frame {t}: {distance}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plot_videos(video1_prenorm, video2_prenorm, distance_list, output_path=os.path.join(output_dir, f\"{video2_name}.mp4\"), fps=fps)\n",
    "plot_distance_chart(distance_list, title=\"Frame-by-Frame Distance\", output_path=os.path.join(output_dir, f\"{video2_name}.png\"))\n",
    "avg_distance = np.mean(distance_list)\n",
    "print(f\"Average distance: {avg_distance:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis: Size S with Registers\n",
    "\n",
    "### Distance Measurements Between Original and Modified Videos\n",
    "\n",
    "| Video 1 | Video 2 | Distance AVG (normalized img) | Distance AVG (unnormalized img) |\n",
    "|---------|---------|-------------------------------|--------------------------------|\n",
    "| Original | No ball | -- | 0.0039 |\n",
    "| Original | No left paddle | -- | 0.0046 |\n",
    "| Original | No right paddle | -- | 0.0067 |\n",
    "| Original | No white bar | -- | 0.0409 |\n",
    "| Original | Add a small 4×4 white area | -- | 0.0146 |\n",
    "| Original | Add a small 4×4 red area | -- | 0.0026 |\n",
    "| Original | Add a small 4×4 green area | -- | 0.0071 |\n",
    "| Original | Add a small 2×2 white area | -- | 0.0068 |\n",
    "| Original | Add one white pixel | -- | 0.0081 |\n",
    "| Original | Add one red pixel | -- | 0.0006 |\n",
    "| Original | Add one green pixel | -- | 0.0007 |\n",
    "\n",
    "**Note:** The base distance resulting from MP4 conversion is 0.0112.\n",
    "\n",
    "- A small pixel region can be less important than the ball (0.0006 < 0.0039 and 0.0026 < 0.0039)\n",
    "- The importance ranking from most to least significant:\n",
    "  1. White bar (0.0409)\n",
    "  2. Right paddle (0.0067)\n",
    "  3. Left paddle (0.0046)\n",
    "  4. Ball (0.0039) ~= Small pixel regions\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
